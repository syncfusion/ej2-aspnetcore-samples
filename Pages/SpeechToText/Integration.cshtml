@page
@using Syncfusion.EJ2
@model EJ2CoreSampleBrowser.Pages.SpeechToText.IntegrationModel

@section ControlsSection {
    <div class="control-section integration-control-section">
        <div class="control-wrapper">
            <div class="integration-speechToText-section">
                <!-- Initialize Toast notification for errors -->
                <ejs-toast id="stt-toast" target=".integration-control-section" cssClass="e-toast-danger" created="onToastCreate">
                    <e-toast-position X="Right"></e-toast-position>
                </ejs-toast>
                <!-- Initialize AI AssistView component -->
                <ejs-aiassistview id="aiAssistView" bannerTemplate="#bannerContent" footerTemplate="#footerContent" promptRequest="onPromptRequest" created="onCreate">
                    <e-aiassistview-toolbarsettings items="@Model.Items" itemClicked="toolbarItemClicked"></e-aiassistview-toolbarsettings>
                </ejs-aiassistview>
            </div>
        </div>
    </div>
}

<style>

    .integration-speechToText-section {
        height: 550px;
        width: 550px;
        margin: 0 auto;
    }

    .integration-speechToText-section .banner-info .e-listen-icon:before {
        font-size: 35px;
    }

    .integration-speechToText-section .banner-info {
        display: flex;
        flex-direction: column;
        justify-content: center;
        height: 330px;
        text-align: center;
    }

    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        width: 40px;
        height: 40px;
        font-size: 20px;
        border: none;
        cursor: pointer;
    }

    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton:not(.e-assist-stop) {
        background: none;
    }

    .e-bigger .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        width: 52px;
        height: 52px;
    }

    .integration-speechToText-section .e-footer-wrapper #speechToText.visible,
    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton.visible {
        display: inline-block;
    }

    .integration-speechToText-section .e-footer-wrapper #speechToText,
    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        display: none;
    }

    @@media only screen and (max-width: 750px) {
        .integration-speechToText-section {
            width: 100%;
        }
    }

    .integration-speechToText-section .e-footer-wrapper {
        display: flex;
        border: 1px solid #c1c1c1;
        padding: 5px 5px 5px 10px;
        margin: 5px 5px 0 5px;
        border-radius: 30px;
    }

    .integration-speechToText-section .e-footer-wrapper .content-editor {
        width: 100%;
        overflow-y: auto;
        font-size: 14px;
        min-height: 25px;
        max-height: 200px;
        padding: 10px;
        scrollbar-color: #c1c1c1 transparent;
    }

    .integration-speechToText-section .e-footer-wrapper .content-editor[contentEditable=true]:empty:before {
        content: attr(placeholder)
    }

    .integration-speechToText-section .option-container {
        align-self: flex-end;
    }
</style>

@section PreScripts {
    <script>
        var aiAssistViewObj;
        var toastObj;
        var assistviewFooter;
        var sendButton;
        var speechToTextObj;

        function onCreate() {
            aiAssistViewObj = ej.base.getComponent(document.getElementById("aiAssistView"), "aiassistview");
            // Initialize Speech-to-Text component
            speechToTextObj = new ej.inputs.SpeechToText({
                transcriptChanged: onTranscriptChange,
                onStop: onListeningStop,
                created: onCreated,
                onError: onErrorHandler,
                cssClass: 'e-flat'
            });
            speechToTextObj.appendTo('#speechToText');
        }

        function onToastCreate() {
            toastObj = ej.base.getComponent(document.getElementById("stt-toast"), "toast");
        }

        // Handles AI prompt requests
        function onPromptRequest(args) {
            setTimeout(function () {
                aiAssistViewObj.addPromptResponse('For real-time prompt processing, connect the AIAssistView component to your preferred AI service.');
                toggleButtons();
            }, 2000);
        }

        // Handles toolbar button clicks
        function toolbarItemClicked(args) {
            if (args.item.iconCss === 'e-icons e-refresh') {
                aiAssistViewObj.prompts = [];
            }
        }

        // Updates transcript in the input area when speech-to-text transcribes
        function onTranscriptChange(args) {
            document.querySelector('#assistview-footer').innerText = args.transcript;
        }

        // Handles actions when speech listening stops
        function onListeningStop() {
            toggleButtons();
        }

        // Handles actions after component creation
        function onCreated() {
            assistviewFooter = document.querySelector('#assistview-footer');
            sendButton = document.querySelector('#assistview-sendButton');
            sendButton.addEventListener('click', sendIconClicked);
            assistviewFooter.addEventListener('input', toggleButtons);

            assistviewFooter.addEventListener('keydown', function (e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                    sendIconClicked();
                    e.preventDefault(); // Prevent the default behavior of the Enter key
                }
        });
            toggleButtons();
        }

        // Toggles the visibility of the send and speech-to-text buttons
        function toggleButtons() {
            var hasText = assistviewFooter.innerText.trim() !== '';
            sendButton.classList.toggle('visible', hasText);
            speechToTextObj.element.classList.toggle('visible', !hasText);
            if (!hasText && (assistviewFooter.innerHTML === '<br>' || !assistviewFooter.innerHTML.trim())) {
                assistviewFooter.innerHTML = '';
            }
        }

        // Handles send button click event
        function sendIconClicked() {
            aiAssistViewObj.executePrompt(assistviewFooter.innerText);
            assistviewFooter.innerText = "";
        }

        // Handles errors and displays toast notifications
        function onErrorHandler(args) {
            toastObj.content = args.errorMessage;
            if (args.error === 'unsupported-browser') {
                this.disabled = true;
                toastObj.show({ timeOut: 0 });
            } else {
                toastObj.show({ timeOut: 5000 });
            }
        }

    </script>

    <script id="bannerContent" type="text/x-jsrender">
        <div class="banner-info">
            <div class="e-icons e-listen-icon"></div>
            <h3>Speech To Text</h3>
            <i>Click the below mic-button to convert your voice to text.</i>
        </div>
    </script>

    <script id="footerContent" type="text/x-jsrender">
        <div class="e-footer-wrapper">
            <div id="assistview-footer" class="content-editor" oninput="toggleButtons" contenteditable="true" placeholder="Click to speak or start typing..."></div>
            <div class="option-container">
                <button id="speechToText"></button>
                <button id="assistview-sendButton" class="e-assist-send e-icons" role="button"></button>
            </div>
        </div>
    </script>
}
@section Meta {
    <meta name="description" content="This example demonstrates the integration of SpeechToText with the AI AssistView in ASP.NET Core. Explore here for more details." />
}

@section ActionDescription {
    <div id="action-description">
        <p>
            This sample demonstrates the integration of SpeechToText with the AI AssistView control. It allows users to convert spoken words into text in real time and use the transcribed content as input for AI-based interactions.
        </p>
    </div>
}
@section Description {
    <div id="description">
        <p>
            In this example, the SpeechToText control captures and transcribes spoken input into text, which is displayed in an editable area. Users can modify the transcribed text or send it directly to the AI AssistView for processing.
        </p>
        <p>
            The AI AssistView responds based on the provided input. A toolbar option is available to clear the conversation history, and a toast notification alerts users to any speech recognition errors.
        </p>
    </div>
}

@section Title {
    <title>ASP.NET Core integration of SpeechToText with the AI AssistView Example - Syncfusion Demos </title>
}
@section Header {
    <h1 class='sb-sample-text'>Example of integration of SpeechToText with the AI AssistView in ASP.NET Core</h1>
}